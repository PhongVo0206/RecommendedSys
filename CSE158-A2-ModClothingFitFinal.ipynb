{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "    for l in open(fname):\n",
    "        if l is \"null\": continue\n",
    "        yield json.loads(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"modcloth_final_data.json\"))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([d for d in data if \"cup size\" in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([d for d in data if \"bra size\" in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([d for d in data if \"height\" in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modData = [d for d in data if \"cup size\" in d and \"bra size\" in d\n",
    "    and \"height\" in d and d['size'] <= 22]\n",
    "len(modData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique([d['cup size'] for d in modData]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique([d['bra size'] for d in modData]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique([d['hips'] for d in modData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique([d['height'] for d in modData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in modData:\n",
    "    h = d['height']\n",
    "    s = h.strip().split()\n",
    "    ft = (int)(s[0].split('ft')[0])\n",
    "    try:\n",
    "        inches = (int)(s[1].split('in')[0])\n",
    "    except:\n",
    "        inches = 0\n",
    "    finally:\n",
    "        height = (ft*12) + inches \n",
    "        d['modHeight'] = height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in modData:\n",
    "#     d['hips'] = int((float)(d['hips']))\n",
    "# modData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catCups = np.unique([d['cup size'] for d in modData])\n",
    "catCupsID = dict(zip(list(catCups),range(len(catCups))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catBra = np.unique([d['bra size'] for d in modData])\n",
    "catBraID = dict(zip(list(catBra),range(len(catBra))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featCups(d):\n",
    "    feat = []\n",
    "    feat = [0] * len(catCupsID)\n",
    "    feat[catCupsID[d['cup size']]] = 1\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featBra(d):\n",
    "    feat = []\n",
    "    feat = [0] * len(catBraID)\n",
    "    feat[catBraID[d['bra size']]] = 1\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in modData:\n",
    "    size = d['size']\n",
    "    if size <= 2:\n",
    "        d['catSize'] = 0\n",
    "    elif size <= 6:\n",
    "        d['catSize'] =1\n",
    "    elif size <= 10:\n",
    "        d['catSize']=2\n",
    "    elif size <= 14:\n",
    "        d['catSize'] = 3\n",
    "    elif size <= 18:\n",
    "        d['catSize'] = 4\n",
    "    else:\n",
    "        d['catSize'] =5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1] + featCups(d) + featBra(d) + [d['modHeight']]  for d in modData] \n",
    "y = [d['catSize'] for d in modData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X)\n",
    "Xtrain = X[:N//2]\n",
    "Xvalid = X[N//2:3*N//4]\n",
    "Xtest = X[3*N//4:]\n",
    "ytrain = y[:N//2]\n",
    "yvalid = y[N//2:3*N//4]\n",
    "ytest = y[3*N//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAcc(model):\n",
    "    # In validation set\n",
    "    # Predict one size\n",
    "    T=0\n",
    "    ypredValid = model.predict(Xvalid)\n",
    "    T = sum([(a == b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "    print(\"In validation set, accuracy when predict one size is:\",format(T/len(yvalid)*100, '.2f'), \"%\", sep=\"\")\n",
    "    # Predict two size\n",
    "    yprob = model.predict_proba(Xvalid)\n",
    "    yprob_ = []\n",
    "    for y in yprob:\n",
    "        sorted_dict = {}\n",
    "        data = dict(zip(range(len(y)),list(y.round(2))))\n",
    "        sorted_y = sorted(data, key=data.get, reverse=True)\n",
    "        for w in sorted_y:\n",
    "            sorted_dict[w] = data[w]\n",
    "        yprob_.append(dict(itertools.islice(sorted_dict.items(), 2)))\n",
    "    y2size = [[list(d.keys())[0], list(d.keys())[1]] for d in yprob_]\n",
    "    T_ = 0\n",
    "    T_ = sum([(a == b[0] or a == b[1]) for (a,b) in zip(yvalid, y2size)])\n",
    "    print(\"In validation set, accuracy when predict two size is:\", format(T_/len(yvalid)*100, '.2f'), \"%\", sep=\"\")\n",
    "    \n",
    "    # In test set\n",
    "    # Predict one size\n",
    "    T=0\n",
    "    ypredTest = model.predict(Xtest)\n",
    "    T = sum([(a == b) for (a,b) in zip(ytest, ypredTest)])\n",
    "    print(\"In test set, accuracy when predict one size is:\",format(T/len(yvalid)*100, '.2f'), \"%\", sep=\"\")\n",
    "    # Predict two size\n",
    "    yprob = model.predict_proba(Xtest)\n",
    "    yprob_ = []\n",
    "    for y in yprob:\n",
    "        sorted_dict = {}\n",
    "        data = dict(zip(range(len(y)),list(y.round(2))))\n",
    "        sorted_y = sorted(data, key=data.get, reverse=True)\n",
    "        for w in sorted_y:\n",
    "            sorted_dict[w] = data[w]\n",
    "        yprob_.append(dict(itertools.islice(sorted_dict.items(), 2)))\n",
    "    y2size = [[list(d.keys())[0], list(d.keys())[1]] for d in yprob_]\n",
    "    T_ = 0\n",
    "    T_ = sum([(a == b[0] or a == b[1]) for (a,b) in zip(ytest, y2size)])\n",
    "    print(\"In test set, accuracy when predict two size is:\", format(T_/len(ytest)*100, '.2f'), \"%\", sep=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNB = GaussianNB()\n",
    "modelNB.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printAcc(modelNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLR = linear_model.LogisticRegression(C=10**4, max_iter=10**4, fit_intercept = False)\n",
    "modelLR.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printAcc(modelLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([d <= 1 for d in abs(ytest - ypredTest)])/len(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='linear', probability=True)\n",
    "svclassifier.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=0\n",
    "ypredValid = svclassifier.predict(Xvalid)\n",
    "T = sum([(a == b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "print(\"In validation set, accuracy when predict one size is:\",format(T/len(yvalid)*100, '.2f'), \"%\", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printAcc(svclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(yvalid,ypredValid2))\n",
    "print(classification_report(yvalid,ypredValid2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([d <= 1 for d in abs(yvalid - ypredValid2)])/len(yvalid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
