{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(fname):\n",
    "    for l in open(fname):\n",
    "        if l is \"null\": continue\n",
    "        yield json.loads(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data...\")\n",
    "data = list(parseData(\"modcloth_final_data.json\"))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'item_id': '123373',\n",
       " 'waist': '29',\n",
       " 'size': 7,\n",
       " 'quality': 5,\n",
       " 'cup size': 'd',\n",
       " 'hips': '38',\n",
       " 'bra size': '34',\n",
       " 'category': 'new',\n",
       " 'bust': '36',\n",
       " 'height': '5ft 6in',\n",
       " 'user_name': 'Emily',\n",
       " 'length': 'just right',\n",
       " 'fit': 'small',\n",
       " 'user_id': '991571'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82790"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([d[' review_text'] for d in data if \" review_text\" in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76065"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([d['review_summary'] for d in data if \"review_summary\" in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76535"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([d for d in data if \"cup size\" in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76772"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([d for d in data if \"bra size\" in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81683"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([d for d in data if \"height\" in d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54130"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modData = [d for d in data if \"bra size\" in d and \"cup size\" in d \n",
    "           and \"height\" in d and (d['category']!='bottoms') and (d['size'] < 22)]\n",
    "len(modData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'aa', 'b', 'c', 'd', 'dd/e', 'ddd/f', 'dddd/g', 'h', 'i', 'j',\n",
       "       'k'], dtype='<U6')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([d['cup size'] for d in modData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique([d['cup size'] for d in modData]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique([d['bra size'] for d in modData]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique([d['hips'] for d in modData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3ft', '3ft 11in', '3ft 3in', '3ft 4in', '3ft 6in', '4ft 10in',\n",
       "       '4ft 11in', '4ft 2in', '4ft 4in', '4ft 7in', '4ft 8in', '4ft 9in',\n",
       "       '5ft', '5ft 10in', '5ft 11in', '5ft 1in', '5ft 2in', '5ft 3in',\n",
       "       '5ft 4in', '5ft 5in', '5ft 6in', '5ft 7in', '5ft 8in', '5ft 9in',\n",
       "       '6ft', '6ft 1in', '6ft 2in', '6ft 3in', '6ft 4in', '6ft 5in',\n",
       "       '6ft 6in', '6ft 8in', '7ft 11in', '7ft 3in', '7ft 5in'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([d['height'] for d in modData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in modData:\n",
    "    h = d['height']\n",
    "    s = h.strip().split()\n",
    "    ft = (int)(s[0].split('ft')[0])\n",
    "    try:\n",
    "        inches = (int)(s[1].split('in')[0])\n",
    "    except:\n",
    "        inches = 0\n",
    "    finally:\n",
    "        height = (ft*12) + inches \n",
    "        d['modHeight'] = height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in modData:\n",
    "#     d['hips'] = int((float)(d['hips']))\n",
    "# modData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'aa': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'dd/e': 5, 'ddd/f': 6, 'dddd/g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11}\n"
     ]
    }
   ],
   "source": [
    "catCups = np.unique([d['cup size'] for d in modData])\n",
    "catCups[0] = 'aa'\n",
    "catCups[1] = 'a'\n",
    "catCupsID = dict(zip(list(catCups),range(len(catCups))))\n",
    "print(catCupsID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "catBra = np.unique([d['bra size'] for d in modData])\n",
    "catBraID = dict(zip(list(catBra),range(len(catBra))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featCups(d):\n",
    "    feat = []\n",
    "    feat = [0] * len(catCupsID)\n",
    "    feat[catCupsID[d['cup size']]] = 1\n",
    "    return [catCupsID[d['cup size']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featBra(d):\n",
    "    feat = []\n",
    "    feat = [0] * len(catBraID)\n",
    "    feat[catBraID[d['bra size']]] = 1\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in modData:\n",
    "    size = d['size']\n",
    "    if size <= 2:\n",
    "        d['catSize'] = 0\n",
    "    elif size <= 6:\n",
    "        d['catSize'] =1\n",
    "    elif size <= 10:\n",
    "        d['catSize']=2\n",
    "    elif size <= 14:\n",
    "        d['catSize'] = 3\n",
    "    elif size <= 18:\n",
    "        d['catSize'] = 4\n",
    "    else:\n",
    "        d['catSize'] =5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAcc(model):\n",
    "    # In validation set\n",
    "    # Predict one size\n",
    "    T=0\n",
    "    ypredValid = model.predict(Xvalid)\n",
    "    T = sum([(a == b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "    print(\"In validation set, accuracy when predict one size is:\",format(T/len(yvalid)*100, '.2f'), \"%\", sep=\"\")\n",
    "    # Predict two size\n",
    "    yprob = model.predict_proba(Xvalid)\n",
    "    yprob_ = []\n",
    "    for y in yprob:\n",
    "        sorted_dict = {}\n",
    "        data = dict(zip(range(len(y)),list(y.round(2))))\n",
    "        sorted_y = sorted(data, key=data.get, reverse=True)\n",
    "        for w in sorted_y:\n",
    "            sorted_dict[w] = data[w]\n",
    "        yprob_.append(dict(itertools.islice(sorted_dict.items(), 2)))\n",
    "    y2size = [[list(d.keys())[0], list(d.keys())[1]] for d in yprob_]\n",
    "    T_ = 0\n",
    "    T_ = sum([(a == b[0] or a == b[1]) for (a,b) in zip(yvalid, y2size)])\n",
    "    print(\"In validation set, accuracy when predict two size is:\", format(T_/len(yvalid)*100, '.2f'), \"%\", sep=\"\")\n",
    "    \n",
    "    # In test set\n",
    "    # Predict one size\n",
    "    T=0\n",
    "    ypredTest = model.predict(Xtest)\n",
    "    T = sum([(a == b) for (a,b) in zip(ytest, ypredTest)])\n",
    "    print(\"In test set, accuracy when predict one size is:\",format(T/len(yvalid)*100, '.2f'), \"%\", sep=\"\")\n",
    "    # Predict two size\n",
    "    yprob = model.predict_proba(Xtest)\n",
    "    yprob_ = []\n",
    "    for y in yprob:\n",
    "        sorted_dict = {}\n",
    "        data = dict(zip(range(len(y)),list(y.round(2))))\n",
    "        sorted_y = sorted(data, key=data.get, reverse=True)\n",
    "        for w in sorted_y:\n",
    "            sorted_dict[w] = data[w]\n",
    "        yprob_.append(dict(itertools.islice(sorted_dict.items(), 2)))\n",
    "    y2size = [[list(d.keys())[0], list(d.keys())[1]] for d in yprob_]\n",
    "    T_ = 0\n",
    "    T_ = sum([(a == b[0] or a == b[1]) for (a,b) in zip(ytest, y2size)])\n",
    "    print(\"In test set, accuracy when predict two size is:\", format(T_/len(ytest)*100, '.2f'), \"%\", sep=\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1] + [(int)(d['bra size'])]  for d in modData] \n",
    "y = [d['catSize'] for d in modData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X)\n",
    "Xtrain = X[:N//2]\n",
    "Xvalid = X[N//2:3*N//4]\n",
    "Xtest = X[3*N//4:]\n",
    "ytrain = y[:N//2]\n",
    "yvalid = y[N//2:3*N//4]\n",
    "ytest = y[3*N//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=False,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLR = linear_model.LogisticRegression(C=10**4, max_iter=10**4, fit_intercept = False)\n",
    "modelLR.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In validation set, accuracy when predict one size is:45.29%\n",
      "In validation set, accuracy when predict two size is:75.01%\n",
      "In test set, accuracy when predict one size is:46.21%\n",
      "In test set, accuracy when predict two size is:73.65%\n"
     ]
    }
   ],
   "source": [
    "printAcc(modelLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[1] + featCups(d) + [(int)(d['bra size'])] + [d['modHeight']]  for d in modData] \n",
    "y = [d['catSize'] for d in modData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X)\n",
    "Xtrain = X[:N//2]\n",
    "Xvalid = X[N//2:3*N//4]\n",
    "Xtest = X[3*N//4:]\n",
    "ytrain = y[:N//2]\n",
    "yvalid = y[N//2:3*N//4]\n",
    "ytest = y[3*N//4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelNB = GaussianNB()\n",
    "modelNB.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In validation set, accuracy when predict one size is:50.33%\n",
      "In validation set, accuracy when predict two size is:79.35%\n",
      "In test set, accuracy when predict one size is:51.38%\n",
      "In test set, accuracy when predict two size is:78.53%\n"
     ]
    }
   ],
   "source": [
    "printAcc(modelNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=False,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=10000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLR = linear_model.LogisticRegression(C=10**4, max_iter=10**4, fit_intercept = False)\n",
    "modelLR.fit(Xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In validation set, accuracy when predict one size is:51.00%\n",
      "In validation set, accuracy when predict two size is:79.90%\n",
      "In test set, accuracy when predict one size is:51.95%\n",
      "In test set, accuracy when predict two size is:78.97%\n"
     ]
    }
   ],
   "source": [
    "printAcc(modelLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([d <= 1 for d in abs(ytest - ypredTest)])/len(ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear', probability=True)\n",
    "# svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T=0\n",
    "# ypredValid = svclassifier.predict(Xvalid)\n",
    "# T = sum([(a == b) for (a,b) in zip(yvalid, ypredValid)])\n",
    "# print(\"In validation set, accuracy when predict one size is:\",format(T/len(yvalid)*100, '.2f'), \"%\", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In validation set, accuracy when predict one size is:51.15%\n",
      "In validation set, accuracy when predict two size is:79.86%\n",
      "In test set, accuracy when predict one size is:52.17%\n",
      "In test set, accuracy when predict two size is:79.24%\n"
     ]
    }
   ],
   "source": [
    "printAcc(svclassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ypredValid2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-aecf33ed1183>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myvalid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mypredValid2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myvalid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mypredValid2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ypredValid2' is not defined"
     ]
    }
   ],
   "source": [
    "# print(confusion_matrix(yvalid,ypredValid2))\n",
    "# print(classification_report(yvalid,ypredValid2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([d <= 1 for d in abs(yvalid - ypredValid2)])/len(yvalid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
